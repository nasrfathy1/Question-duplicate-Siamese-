{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install trax\n\nimport trax\nimport trax.layers as tl\nfrom trax.supervised.training import TrainTask,EvalTask,Loop\nimport pandas as pd\n\nfrom nltk.tokenize import word_tokenize\nimport numpy as np\nimport random as rnd\nfrom trax.supervised.training import Loop,TrainTask,EvalTask\nimport trax.fastmath.numpy as fastnp","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:45:03.932491Z","iopub.execute_input":"2023-06-02T16:45:03.932842Z","iopub.status.idle":"2023-06-02T16:46:56.293100Z","shell.execute_reply.started":"2023-06-02T16:45:03.932812Z","shell.execute_reply":"2023-06-02T16:46:56.292124Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting trax\n  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: gym in /opt/conda/lib/python3.10/site-packages (from trax) (0.26.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from trax) (5.9.4)\nCollecting gin-config\n  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from trax) (0.4.7+cuda11.cudnn82)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from trax) (1.4.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from trax) (1.9.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from trax) (3.6.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from trax) (1.23.5)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from trax) (4.9.0)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from trax) (2.11.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from trax) (1.16.0)\nCollecting funcsigs\n  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\nRequirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from trax) (0.4.8)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym->trax) (0.0.8)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym->trax) (2.2.1)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->trax) (3.3.0)\nRequirement already satisfied: ml-dtypes>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from jax->trax) (0.1.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (9.5.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (4.39.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (1.4.4)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (21.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (1.0.7)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (8.1.3)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (1.2.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.3)\nRequirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.2.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.1.8)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (3.20.3)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (1.15.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.28.2)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (4.64.1)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.10.2)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.14.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->trax) (0.12.0)\nRequirement already satisfied: tensorflow<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->trax) (2.11.0)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (4.5.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (3.15.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (5.12.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.26.15)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (23.3.3)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.53.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (59.8.0)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.6.3)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.8.0)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.29.0)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.0)\nCollecting protobuf\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (16.0.0)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.59.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.17.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.8.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.2.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.6.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.4.3)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.6)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.8)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (5.3.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.2.2)\nInstalling collected packages: gin-config, funcsigs, protobuf, trax\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkfp 1.8.20 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.86.0 which is incompatible.\nkfp 1.8.20 requires PyYAML<6,>=5.3, but you have pyyaml 6.0 which is incompatible.\ngcsfs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2023.4.0 which is incompatible.\ncudf 23.4.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\nbeatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed funcsigs-1.0.2 gin-config-0.5.0 protobuf-3.19.6 trax-1.4.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv(r'/kaggle/input/first-quora-dataset/q_quora.csv')\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:56.299230Z","iopub.execute_input":"2023-06-02T16:46:56.302570Z","iopub.status.idle":"2023-06-02T16:46:58.148442Z","shell.execute_reply.started":"2023-06-02T16:46:56.302533Z","shell.execute_reply":"2023-06-02T16:46:58.147284Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/4072098737.py:1: DtypeWarning: Columns (7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n  data=pd.read_csv(r'/kaggle/input/first-quora-dataset/q_quora.csv')\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2 is_duplicate Unnamed: 6  \\\n0  What is the step by step guide to invest in sh...            0        NaN   \n1  What would happen if the Indian government sto...            0        NaN   \n2  How can Internet speed be increased by hacking...            0        NaN   \n3  Find the remainder when [math]23^{24}[/math] i...            0        NaN   \n4            Which fish would survive in salt water?            0        NaN   \n\n  Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  Unnamed: 12  \n0        NaN        NaN        NaN         NaN         NaN          NaN  \n1        NaN        NaN        NaN         NaN         NaN          NaN  \n2        NaN        NaN        NaN         NaN         NaN          NaN  \n3        NaN        NaN        NaN         NaN         NaN          NaN  \n4        NaN        NaN        NaN         NaN         NaN          NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>Unnamed: 6</th>\n      <th>Unnamed: 7</th>\n      <th>Unnamed: 8</th>\n      <th>Unnamed: 9</th>\n      <th>Unnamed: 10</th>\n      <th>Unnamed: 11</th>\n      <th>Unnamed: 12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:58.150414Z","iopub.execute_input":"2023-06-02T16:46:58.150830Z","iopub.status.idle":"2023-06-02T16:46:59.033438Z","shell.execute_reply.started":"2023-06-02T16:46:58.150790Z","shell.execute_reply":"2023-06-02T16:46:59.032412Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 404351 entries, 0 to 404350\nData columns (total 13 columns):\n #   Column        Non-Null Count   Dtype  \n---  ------        --------------   -----  \n 0   id            404351 non-null  int64  \n 1   qid1          404351 non-null  int64  \n 2   qid2          404351 non-null  int64  \n 3   question1     404350 non-null  object \n 4   question2     404349 non-null  object \n 5   is_duplicate  404351 non-null  object \n 6   Unnamed: 6    337 non-null     object \n 7   Unnamed: 7    27 non-null      object \n 8   Unnamed: 8    8 non-null       object \n 9   Unnamed: 9    3 non-null       object \n 10  Unnamed: 10   2 non-null       object \n 11  Unnamed: 11   2 non-null       object \n 12  Unnamed: 12   2 non-null       float64\ndtypes: float64(1), int64(3), object(9)\nmemory usage: 40.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"duplicate_question=data[data['is_duplicate']=='1'].iloc[:,3:5]\nlen(duplicate_question)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.036197Z","iopub.execute_input":"2023-06-02T16:46:59.039534Z","iopub.status.idle":"2023-06-02T16:46:59.143099Z","shell.execute_reply.started":"2023-06-02T16:46:59.039494Z","shell.execute_reply":"2023-06-02T16:46:59.142007Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"149267"},"metadata":{}}]},{"cell_type":"code","source":"#duplicate_question=duplicate_question[:100000]","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.144607Z","iopub.execute_input":"2023-06-02T16:46:59.146580Z","iopub.status.idle":"2023-06-02T16:46:59.151586Z","shell.execute_reply.started":"2023-06-02T16:46:59.146536Z","shell.execute_reply":"2023-06-02T16:46:59.150231Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"duplicate_question.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.153714Z","iopub.execute_input":"2023-06-02T16:46:59.154583Z","iopub.status.idle":"2023-06-02T16:46:59.171198Z","shell.execute_reply.started":"2023-06-02T16:46:59.154540Z","shell.execute_reply":"2023-06-02T16:46:59.169950Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                            question1  \\\n5   Astrology: I am a Capricorn Sun Cap moon and c...   \n7                      How can I be a good geologist?   \n11        How do I read and find my YouTube comments?   \n12               What can make Physics easy to learn?   \n13        What was your first sexual experience like?   \n\n                                            question2  \n5   I'm a triple Capricorn (Sun, Moon and ascendan...  \n7           What should I do to be a great geologist?  \n11             How can I see all my Youtube comments?  \n12            How can you make physics easy to learn?  \n13             What was your first sexual experience?  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>How can I be a good geologist?</td>\n      <td>What should I do to be a great geologist?</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>How do I read and find my YouTube comments?</td>\n      <td>How can I see all my Youtube comments?</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>What can make Physics easy to learn?</td>\n      <td>How can you make physics easy to learn?</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>What was your first sexual experience like?</td>\n      <td>What was your first sexual experience?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"duplicate_question.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.172657Z","iopub.execute_input":"2023-06-02T16:46:59.173664Z","iopub.status.idle":"2023-06-02T16:46:59.285155Z","shell.execute_reply.started":"2023-06-02T16:46:59.173625Z","shell.execute_reply":"2023-06-02T16:46:59.284214Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"question1    0\nquestion2    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"duplicate_question.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.286653Z","iopub.execute_input":"2023-06-02T16:46:59.287466Z","iopub.status.idle":"2023-06-02T16:46:59.400195Z","shell.execute_reply.started":"2023-06-02T16:46:59.287429Z","shell.execute_reply":"2023-06-02T16:46:59.399187Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"train_size=int(len(duplicate_question)*.8)\nval_size=int(len(duplicate_question)*.9)\n\ntrain_data=duplicate_question[:train_size]\nval_data=duplicate_question[train_size:val_size]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.401543Z","iopub.execute_input":"2023-06-02T16:46:59.402609Z","iopub.status.idle":"2023-06-02T16:46:59.408786Z","shell.execute_reply.started":"2023-06-02T16:46:59.402566Z","shell.execute_reply":"2023-06-02T16:46:59.407619Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_data=data.iloc[:,3:6][0:1000]\ntest_data.is_duplicate.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.414940Z","iopub.execute_input":"2023-06-02T16:46:59.415377Z","iopub.status.idle":"2023-06-02T16:46:59.446253Z","shell.execute_reply.started":"2023-06-02T16:46:59.415337Z","shell.execute_reply":"2023-06-02T16:46:59.445187Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0                                                                                                                                                       618\n1                                                                                                                                                       380\nDo bullets travel faster than the speed of sound when shot from a gun? If not, is it possible? If they do, what gun and how much devastation occurs?      1\nMy sister told my crush that I like her without me asking her to do so. What should I do now?                                                             1\nName: is_duplicate, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_data=test_data[test_data.is_duplicate.isin(['0','1'])]\nx_test=test_data.iloc[:,0:2]\ny_test=test_data.is_duplicate.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.448411Z","iopub.execute_input":"2023-06-02T16:46:59.448945Z","iopub.status.idle":"2023-06-02T16:46:59.467074Z","shell.execute_reply.started":"2023-06-02T16:46:59.448909Z","shell.execute_reply":"2023-06-02T16:46:59.466090Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x_test.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.469998Z","iopub.execute_input":"2023-06-02T16:46:59.470942Z","iopub.status.idle":"2023-06-02T16:46:59.478939Z","shell.execute_reply.started":"2023-06-02T16:46:59.470904Z","shell.execute_reply":"2023-06-02T16:46:59.477983Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((998, 2), (998,))"},"metadata":{}}]},{"cell_type":"code","source":"print('Train data shape is :',train_data.shape)\nprint('Val data shape is :',val_data.shape)\nprint('Test data shape is :',test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.480602Z","iopub.execute_input":"2023-06-02T16:46:59.481290Z","iopub.status.idle":"2023-06-02T16:46:59.490318Z","shell.execute_reply.started":"2023-06-02T16:46:59.481240Z","shell.execute_reply":"2023-06-02T16:46:59.489243Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Train data shape is : (119413, 2)\nVal data shape is : (14927, 2)\nTest data shape is : (998, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_vovap(data):\n    vocab={'<pad>':0,'<unknow>':1}\n    question1=data['question1']\n    question2=data['question2']\n    for question in question1:\n        words=word_tokenize(question)\n        for word in words:\n            if word not in list(vocab):\n                vocab[word]=len(vocab)\n    for question in question2:\n        words=word_tokenize(question)\n        for word in words:\n            if word not in list(vocab):\n                vocab[word]=len(vocab)\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.491670Z","iopub.execute_input":"2023-06-02T16:46:59.493610Z","iopub.status.idle":"2023-06-02T16:46:59.501612Z","shell.execute_reply.started":"2023-06-02T16:46:59.493583Z","shell.execute_reply":"2023-06-02T16:46:59.500452Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vocab=get_vovap(train_data[0:int(len(train_data)*.7)])\nlen(vocab)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:46:59.502937Z","iopub.execute_input":"2023-06-02T16:46:59.503439Z","iopub.status.idle":"2023-06-02T17:00:35.109996Z","shell.execute_reply.started":"2023-06-02T16:46:59.503404Z","shell.execute_reply":"2023-06-02T17:00:35.109099Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"32056"},"metadata":{}}]},{"cell_type":"code","source":"def get_tensor(question):\n    tensor1=[]\n    tensor2=[]\n    question1=word_tokenize(question[0])\n    question2=word_tokenize(question[1])\n    for i in question1:\n        tensor1.append(vocab.get(i,1))\n    for i in question2:\n        tensor2.append(vocab.get(i,1))\n    return tensor1,tensor2","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.111608Z","iopub.execute_input":"2023-06-02T17:00:35.112663Z","iopub.status.idle":"2023-06-02T17:00:35.119370Z","shell.execute_reply.started":"2023-06-02T17:00:35.112624Z","shell.execute_reply":"2023-06-02T17:00:35.118411Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x,y=get_tensor(train_data.iloc[0])\nprint('sample from question1:',x)\nprint('sample from question2:',y)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.120898Z","iopub.execute_input":"2023-06-02T17:00:35.121415Z","iopub.status.idle":"2023-06-02T17:00:35.145577Z","shell.execute_reply.started":"2023-06-02T17:00:35.121362Z","shell.execute_reply":"2023-06-02T17:00:35.144712Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"sample from question1: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\nsample from question2: [4, 993, 6, 3949, 7, 268, 8, 124, 6368, 11, 20499, 169, 7, 270, 33, 16, 372, 18, 19, 20, 21]\n","output_type":"stream"}]},{"cell_type":"code","source":"def generator(data):\n    idx=0\n    while True:\n        if idx>=len(data):\n            idx=0\n        questions=data.iloc[idx]\n        tensor1,tensor2=get_tensor(questions)\n        idx+=1\n        tensor1,tensor2=np.array(tensor1),np.array(tensor2)\n        yield tensor1,tensor2 \n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.146783Z","iopub.execute_input":"2023-06-02T17:00:35.148741Z","iopub.status.idle":"2023-06-02T17:00:35.157690Z","shell.execute_reply.started":"2023-06-02T17:00:35.148704Z","shell.execute_reply":"2023-06-02T17:00:35.156724Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x,y=next(generator(train_data))\nx.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.159341Z","iopub.execute_input":"2023-06-02T17:00:35.159754Z","iopub.status.idle":"2023-06-02T17:00:35.173301Z","shell.execute_reply.started":"2023-06-02T17:00:35.159720Z","shell.execute_reply":"2023-06-02T17:00:35.172233Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"((20,), (21,))"},"metadata":{}}]},{"cell_type":"code","source":"boundaries =  [8,   16,  32, 64, 128, 256, 512]\nbatch_sizes = [256,128, 64, 32, 16,    8,   4,  2]\n\n\ngenerate_train_data=trax.data.BucketByLength(boundaries,batch_sizes,length_keys=[0,1])(generator(train_data))\ngenerate_val_data=trax.data.BucketByLength(boundaries,batch_sizes,length_keys=[0,1])(generator(val_data))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.174581Z","iopub.execute_input":"2023-06-02T17:00:35.175483Z","iopub.status.idle":"2023-06-02T17:00:35.182155Z","shell.execute_reply.started":"2023-06-02T17:00:35.175424Z","shell.execute_reply":"2023-06-02T17:00:35.181308Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"x,y=next(generate_train_data)\nx.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.183498Z","iopub.execute_input":"2023-06-02T17:00:35.184533Z","iopub.status.idle":"2023-06-02T17:00:35.288887Z","shell.execute_reply.started":"2023-06-02T17:00:35.184499Z","shell.execute_reply":"2023-06-02T17:00:35.288008Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"((128, 16), (128, 16))"},"metadata":{}}]},{"cell_type":"code","source":"# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: TripletLossFn\ndef TripletLossFn(v1, v2, margin=0.25):\n    \"\"\"Custom Loss function.\n\n    Args:\n        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n        margin (float, optional): Desired margin. Defaults to 0.25.\n\n    Returns:\n        jax.interpreters.xla.DeviceArray: Triplet Loss.\n    \"\"\"\n    ### START CODE HERE (Replace instances of 'None' with your code) ###\n    # use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)\n    scores = fastnp.dot(v1,v2.T) # pairwise cosine sim   \n    # calculate new batch size\n    batch_size = len(scores)\n    # use fastnp to grab all postive `diagonal` entries in `scores`\n    positive = fastnp.diagonal(scores) # the positive ones (duplicates)\n    # subtract `fastnp.eye(batch_size)` out of 1.0 and do element-wise multiplication with `scores`\n    negative_zero_on_duplicate = scores * (1.0 - fastnp.eye(batch_size))\n    # use `fastnp.sum` on `negative_zero_on_duplicate` for `axis= None\n    mean_negative = fastnp.sum(negative_zero_on_duplicate,axis=1) / (batch_size - 1)\n    # create a composition of two masks: \n    # the first mask to extract the diagonal elements, \n    # the second mask to extract elements in the negative_zero_on_duplicate matrix that are larger than the elements in the diagonal \n    mask_exclude_positives = (np.identity(batch_size)==1)|(negative_zero_on_duplicate > positive.reshape(batch_size,1))\n    # multiply `mask_exclude_positives` with 2.0 and subtract it out of `negative_zero_on_duplicate`\n    negative_without_positive = negative_zero_on_duplicate - 2.0 * mask_exclude_positives\n    # take the row by row `max` of `negative_without_positive`. \n    # Hint: negative_without_positive.max(axis = [?])  \n    closest_negative = negative_without_positive.max(axis=1)\n    # compute `fastnp.maximum` among 0.0 and `A`\n    # where A = subtract `positive` from `margin` and add `closest_negative`\n    # IMPORTANT: DO NOT create an extra variable 'A'\n    triplet_loss1 = fastnp.maximum(0,margin - positive + closest_negative)\n    # compute `fastnp.maximum` among 0.0 and `B`\n    # where B = ubtract `positive` from `margin` and add `mean_negative`\n    # IMPORTANT: DO NOT create an extra variable 'B'\n    triplet_loss2 = fastnp.maximum(0,margin - positive + mean_negative)\n    # add the two losses together and take the `fastnp.sum` of it    \n    triplet_loss = fastnp.sum(triplet_loss1 + triplet_loss2)\n    ### END CODE HERE ###\n    \n    return triplet_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.290251Z","iopub.execute_input":"2023-06-02T17:00:35.290834Z","iopub.status.idle":"2023-06-02T17:00:35.301089Z","shell.execute_reply.started":"2023-06-02T17:00:35.290796Z","shell.execute_reply":"2023-06-02T17:00:35.300222Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\nv2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\nprint(\"Triplet Loss:\", TripletLossFn(v1,v2))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:35.302975Z","iopub.execute_input":"2023-06-02T17:00:35.303335Z","iopub.status.idle":"2023-06-02T17:00:48.191032Z","shell.execute_reply.started":"2023-06-02T17:00:35.303303Z","shell.execute_reply":"2023-06-02T17:00:48.189942Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Triplet Loss: 0.7035077\n","output_type":"stream"}]},{"cell_type":"code","source":"from functools import partial\ndef TripletLoss(margin=0.25):\n    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n    return tl.Fn('TripletLoss', triplet_loss_fn)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.192763Z","iopub.execute_input":"2023-06-02T17:00:48.193423Z","iopub.status.idle":"2023-06-02T17:00:48.199111Z","shell.execute_reply.started":"2023-06-02T17:00:48.193384Z","shell.execute_reply":"2023-06-02T17:00:48.198005Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def normalize(x):  # normalizes the vectors to have L2 norm 1\n        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.200600Z","iopub.execute_input":"2023-06-02T17:00:48.201635Z","iopub.status.idle":"2023-06-02T17:00:48.216946Z","shell.execute_reply.started":"2023-06-02T17:00:48.201598Z","shell.execute_reply":"2023-06-02T17:00:48.216034Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def model(d_model):\n    model=tl.Serial([tl.Embedding(len(vocab),d_model),\n               tl.LSTM(d_model),\n               tl.Mean(axis=1),\n               tl.Fn('Normalize',lambda x:normalize(x))\n               \n    ])\n    siamese=tl.Parallel(model,model)\n    return(siamese)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.217886Z","iopub.execute_input":"2023-06-02T17:00:48.218151Z","iopub.status.idle":"2023-06-02T17:00:48.230856Z","shell.execute_reply.started":"2023-06-02T17:00:48.218128Z","shell.execute_reply":"2023-06-02T17:00:48.229965Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(model(512))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.232898Z","iopub.execute_input":"2023-06-02T17:00:48.233795Z","iopub.status.idle":"2023-06-02T17:00:48.243299Z","shell.execute_reply.started":"2023-06-02T17:00:48.233757Z","shell.execute_reply":"2023-06-02T17:00:48.242405Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Parallel_in2_out2[\n  Serial[\n    Embedding_32056_512\n    LSTM_512\n    Mean\n    Normalize\n  ]\n  Serial[\n    Embedding_32056_512\n    LSTM_512\n    Mean\n    Normalize\n  ]\n]\n","output_type":"stream"}]},{"cell_type":"code","source":"def learning_tasks(model,n_step):\n    training=TrainTask(generate_train_data,loss_layer=TripletLoss(),\n                       optimizer=trax.optimizers.Adam(0.001),\n                       n_steps_per_checkpoint=100,)\n    \n    evaltion=EvalTask(generate_val_data,\n                      metrics=[TripletLoss()])\n    \n    trainig_loop=Loop(model,training,eval_tasks=[evaltion],\n                      output_dir='/kaggle/working/model')\n    \n    \n    trainig_loop.run(n_step)\n    return(trainig_loop)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.249389Z","iopub.execute_input":"2023-06-02T17:00:48.250387Z","iopub.status.idle":"2023-06-02T17:00:48.257314Z","shell.execute_reply.started":"2023-06-02T17:00:48.250350Z","shell.execute_reply":"2023-06-02T17:00:48.256486Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"Siamese=model(512)\nn_step=int((train_size/32))*5\nprint(n_step)\nmodel=learning_tasks(Siamese,n_step)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T17:00:48.258704Z","iopub.execute_input":"2023-06-02T17:00:48.259108Z","iopub.status.idle":"2023-06-02T18:06:41.370074Z","shell.execute_reply.started":"2023-06-02T17:00:48.259074Z","shell.execute_reply":"2023-06-02T18:06:41.368995Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"18655\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/jax/_src/xla_bridge.py:658: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n","output_type":"stream"},{"name":"stdout","text":"\nStep      1: Total number of trainable weights: 18511872\nStep      1: Ran 1 train steps in 10.89 secs\nStep      1: train TripletLoss |  15.74986649\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n","output_type":"stream"},{"name":"stdout","text":"Step      1: eval  TripletLoss |  31.99929810\n\nStep    100: Ran 99 train steps in 28.24 secs\nStep    100: train TripletLoss |  22.25253677\nStep    100: eval  TripletLoss |  10.21340752\n\nStep    200: Ran 100 train steps in 19.82 secs\nStep    200: train TripletLoss |  16.36700630\nStep    200: eval  TripletLoss |  15.97921753\n\nStep    300: Ran 100 train steps in 19.95 secs\nStep    300: train TripletLoss |  14.20250607\nStep    300: eval  TripletLoss |  14.24788475\n\nStep    400: Ran 100 train steps in 21.00 secs\nStep    400: train TripletLoss |  12.17187691\nStep    400: eval  TripletLoss |  5.31993961\n\nStep    500: Ran 100 train steps in 21.50 secs\nStep    500: train TripletLoss |  9.83489037\nStep    500: eval  TripletLoss |  8.57252979\n\nStep    600: Ran 100 train steps in 21.59 secs\nStep    600: train TripletLoss |  8.13150692\nStep    600: eval  TripletLoss |  7.35132790\n\nStep    700: Ran 100 train steps in 21.95 secs\nStep    700: train TripletLoss |  7.08531952\nStep    700: eval  TripletLoss |  3.58565426\n\nStep    800: Ran 100 train steps in 22.28 secs\nStep    800: train TripletLoss |  5.86570740\nStep    800: eval  TripletLoss |  5.87721443\n\nStep    900: Ran 100 train steps in 21.93 secs\nStep    900: train TripletLoss |  5.23330688\nStep    900: eval  TripletLoss |  14.46036243\n\nStep   1000: Ran 100 train steps in 21.73 secs\nStep   1000: train TripletLoss |  4.62657404\nStep   1000: eval  TripletLoss |  4.06667662\n\nStep   1100: Ran 100 train steps in 22.05 secs\nStep   1100: train TripletLoss |  4.13206387\nStep   1100: eval  TripletLoss |  2.26675773\n\nStep   1200: Ran 100 train steps in 22.20 secs\nStep   1200: train TripletLoss |  3.76836467\nStep   1200: eval  TripletLoss |  3.46549654\n\nStep   1300: Ran 100 train steps in 21.79 secs\nStep   1300: train TripletLoss |  3.42830610\nStep   1300: eval  TripletLoss |  3.24420166\n\nStep   1400: Ran 100 train steps in 22.10 secs\nStep   1400: train TripletLoss |  2.98240352\nStep   1400: eval  TripletLoss |  1.37464452\n\nStep   1500: Ran 100 train steps in 22.13 secs\nStep   1500: train TripletLoss |  2.71762180\nStep   1500: eval  TripletLoss |  2.94041681\n\nStep   1600: Ran 100 train steps in 21.71 secs\nStep   1600: train TripletLoss |  2.50396991\nStep   1600: eval  TripletLoss |  1.89535856\n\nStep   1700: Ran 100 train steps in 22.03 secs\nStep   1700: train TripletLoss |  2.30129457\nStep   1700: eval  TripletLoss |  1.61104202\n\nStep   1800: Ran 100 train steps in 22.20 secs\nStep   1800: train TripletLoss |  2.13348532\nStep   1800: eval  TripletLoss |  2.39964294\n\nStep   1900: Ran 100 train steps in 22.03 secs\nStep   1900: train TripletLoss |  1.99317825\nStep   1900: eval  TripletLoss |  2.31371665\n\nStep   2000: Ran 100 train steps in 21.38 secs\nStep   2000: train TripletLoss |  1.95379329\nStep   2000: eval  TripletLoss |  0.99557954\n\nStep   2100: Ran 100 train steps in 22.16 secs\nStep   2100: train TripletLoss |  1.70398450\nStep   2100: eval  TripletLoss |  1.48427761\n\nStep   2200: Ran 100 train steps in 21.89 secs\nStep   2200: train TripletLoss |  1.63503551\nStep   2200: eval  TripletLoss |  2.53209352\n\nStep   2300: Ran 100 train steps in 22.03 secs\nStep   2300: train TripletLoss |  1.51206315\nStep   2300: eval  TripletLoss |  7.31666660\n\nStep   2400: Ran 100 train steps in 22.29 secs\nStep   2400: train TripletLoss |  1.41659319\nStep   2400: eval  TripletLoss |  1.26246095\n\nStep   2500: Ran 100 train steps in 21.88 secs\nStep   2500: train TripletLoss |  1.22970963\nStep   2500: eval  TripletLoss |  1.82099044\n\nStep   2600: Ran 100 train steps in 21.78 secs\nStep   2600: train TripletLoss |  1.22750688\nStep   2600: eval  TripletLoss |  1.37565958\n\nStep   2700: Ran 100 train steps in 22.22 secs\nStep   2700: train TripletLoss |  1.12343478\nStep   2700: eval  TripletLoss |  0.87865663\n\nStep   2800: Ran 100 train steps in 21.90 secs\nStep   2800: train TripletLoss |  1.14935386\nStep   2800: eval  TripletLoss |  1.53974879\n\nStep   2900: Ran 100 train steps in 22.07 secs\nStep   2900: train TripletLoss |  1.08011830\nStep   2900: eval  TripletLoss |  1.72063470\n\nStep   3000: Ran 100 train steps in 21.32 secs\nStep   3000: train TripletLoss |  1.10265195\nStep   3000: eval  TripletLoss |  1.14079750\n\nStep   3100: Ran 100 train steps in 21.87 secs\nStep   3100: train TripletLoss |  1.00033987\nStep   3100: eval  TripletLoss |  1.04266226\n\nStep   3200: Ran 100 train steps in 21.75 secs\nStep   3200: train TripletLoss |  1.00229573\nStep   3200: eval  TripletLoss |  1.18459105\n\nStep   3300: Ran 100 train steps in 21.36 secs\nStep   3300: train TripletLoss |  0.93527430\nStep   3300: eval  TripletLoss |  1.73983896\n\nStep   3400: Ran 100 train steps in 21.85 secs\nStep   3400: train TripletLoss |  0.89988941\nStep   3400: eval  TripletLoss |  0.71247697\n\nStep   3500: Ran 100 train steps in 21.94 secs\nStep   3500: train TripletLoss |  0.78301024\nStep   3500: eval  TripletLoss |  1.23463106\n\nStep   3600: Ran 100 train steps in 21.34 secs\nStep   3600: train TripletLoss |  0.79137564\nStep   3600: eval  TripletLoss |  6.08390856\n\nStep   3700: Ran 100 train steps in 21.92 secs\nStep   3700: train TripletLoss |  0.74368048\nStep   3700: eval  TripletLoss |  0.93397629\n\nStep   3800: Ran 100 train steps in 21.60 secs\nStep   3800: train TripletLoss |  0.78612036\nStep   3800: eval  TripletLoss |  0.45563164\n\nStep   3900: Ran 100 train steps in 21.39 secs\nStep   3900: train TripletLoss |  0.73472029\nStep   3900: eval  TripletLoss |  1.18667221\n\nStep   4000: Ran 100 train steps in 21.52 secs\nStep   4000: train TripletLoss |  0.80609173\nStep   4000: eval  TripletLoss |  1.25797057\n\nStep   4100: Ran 100 train steps in 21.66 secs\nStep   4100: train TripletLoss |  0.71466994\nStep   4100: eval  TripletLoss |  1.36051130\n\nStep   4200: Ran 100 train steps in 21.00 secs\nStep   4200: train TripletLoss |  0.70836473\nStep   4200: eval  TripletLoss |  1.29857707\n\nStep   4300: Ran 100 train steps in 21.56 secs\nStep   4300: train TripletLoss |  0.70164603\nStep   4300: eval  TripletLoss |  0.54603326\n\nStep   4400: Ran 100 train steps in 21.34 secs\nStep   4400: train TripletLoss |  0.67453521\nStep   4400: eval  TripletLoss |  0.92015415\n\nStep   4500: Ran 100 train steps in 21.00 secs\nStep   4500: train TripletLoss |  0.64401770\nStep   4500: eval  TripletLoss |  0.99873453\n\nStep   4600: Ran 100 train steps in 21.49 secs\nStep   4600: train TripletLoss |  0.62367409\nStep   4600: eval  TripletLoss |  1.21516609\n\nStep   4700: Ran 100 train steps in 21.53 secs\nStep   4700: train TripletLoss |  0.57231331\nStep   4700: eval  TripletLoss |  4.45584011\n\nStep   4800: Ran 100 train steps in 20.98 secs\nStep   4800: train TripletLoss |  0.58572823\nStep   4800: eval  TripletLoss |  1.52306986\n\nStep   4900: Ran 100 train steps in 21.63 secs\nStep   4900: train TripletLoss |  0.64075524\nStep   4900: eval  TripletLoss |  0.71677202\n\nStep   5000: Ran 100 train steps in 21.56 secs\nStep   5000: train TripletLoss |  0.59410650\nStep   5000: eval  TripletLoss |  1.60942304\n\nStep   5100: Ran 100 train steps in 20.85 secs\nStep   5100: train TripletLoss |  0.57140678\nStep   5100: eval  TripletLoss |  0.74934345\n\nStep   5200: Ran 100 train steps in 21.30 secs\nStep   5200: train TripletLoss |  0.58659011\nStep   5200: eval  TripletLoss |  0.76435983\n\nStep   5300: Ran 100 train steps in 21.48 secs\nStep   5300: train TripletLoss |  0.54564279\nStep   5300: eval  TripletLoss |  1.33736122\n\nStep   5400: Ran 100 train steps in 20.85 secs\nStep   5400: train TripletLoss |  0.54274452\nStep   5400: eval  TripletLoss |  1.20289516\n\nStep   5500: Ran 100 train steps in 21.24 secs\nStep   5500: train TripletLoss |  0.53500098\nStep   5500: eval  TripletLoss |  0.58873475\n\nStep   5600: Ran 100 train steps in 21.38 secs\nStep   5600: train TripletLoss |  0.50193703\nStep   5600: eval  TripletLoss |  1.16705132\n\nStep   5700: Ran 100 train steps in 20.90 secs\nStep   5700: train TripletLoss |  0.51353943\nStep   5700: eval  TripletLoss |  1.42423582\n\nStep   5800: Ran 100 train steps in 21.28 secs\nStep   5800: train TripletLoss |  0.50991738\nStep   5800: eval  TripletLoss |  0.37577456\n\nStep   5900: Ran 100 train steps in 20.98 secs\nStep   5900: train TripletLoss |  0.55137575\nStep   5900: eval  TripletLoss |  0.70254868\n\nStep   6000: Ran 100 train steps in 20.73 secs\nStep   6000: train TripletLoss |  0.51283967\nStep   6000: eval  TripletLoss |  4.45695686\n\nStep   6100: Ran 100 train steps in 21.01 secs\nStep   6100: train TripletLoss |  0.53695869\nStep   6100: eval  TripletLoss |  0.74139476\n\nStep   6200: Ran 100 train steps in 21.04 secs\nStep   6200: train TripletLoss |  0.50171548\nStep   6200: eval  TripletLoss |  0.60521913\n\nStep   6300: Ran 100 train steps in 20.60 secs\nStep   6300: train TripletLoss |  0.47886467\nStep   6300: eval  TripletLoss |  1.24712634\n\nStep   6400: Ran 100 train steps in 21.22 secs\nStep   6400: train TripletLoss |  0.45836312\nStep   6400: eval  TripletLoss |  1.18304777\n\nStep   6500: Ran 100 train steps in 20.87 secs\nStep   6500: train TripletLoss |  0.48816574\nStep   6500: eval  TripletLoss |  1.54851246\n\nStep   6600: Ran 100 train steps in 20.56 secs\nStep   6600: train TripletLoss |  0.46116492\nStep   6600: eval  TripletLoss |  0.78796506\n\nStep   6700: Ran 100 train steps in 20.93 secs\nStep   6700: train TripletLoss |  0.46379817\nStep   6700: eval  TripletLoss |  1.49896336\n\nStep   6800: Ran 100 train steps in 21.10 secs\nStep   6800: train TripletLoss |  0.42616874\nStep   6800: eval  TripletLoss |  0.50904059\n\nStep   6900: Ran 100 train steps in 20.70 secs\nStep   6900: train TripletLoss |  0.46728882\nStep   6900: eval  TripletLoss |  0.54356521\n\nStep   7000: Ran 100 train steps in 21.50 secs\nStep   7000: train TripletLoss |  0.51212507\nStep   7000: eval  TripletLoss |  0.91883963\n\nStep   7100: Ran 100 train steps in 21.07 secs\nStep   7100: train TripletLoss |  0.45629284\nStep   7100: eval  TripletLoss |  0.77015442\n\nStep   7200: Ran 100 train steps in 20.82 secs\nStep   7200: train TripletLoss |  0.44494900\nStep   7200: eval  TripletLoss |  0.69979572\n\nStep   7300: Ran 100 train steps in 21.02 secs\nStep   7300: train TripletLoss |  0.46562174\nStep   7300: eval  TripletLoss |  3.42060232\n\nStep   7400: Ran 100 train steps in 20.96 secs\nStep   7400: train TripletLoss |  0.44992930\nStep   7400: eval  TripletLoss |  0.82903093\n\nStep   7500: Ran 100 train steps in 20.49 secs\nStep   7500: train TripletLoss |  0.44649702\nStep   7500: eval  TripletLoss |  1.01595259\n\nStep   7600: Ran 100 train steps in 23.85 secs\nStep   7600: train TripletLoss |  0.41731712\nStep   7600: eval  TripletLoss |  0.78449357\n\nStep   7700: Ran 100 train steps in 20.98 secs\nStep   7700: train TripletLoss |  0.39730987\nStep   7700: eval  TripletLoss |  0.91785127\n\nStep   7800: Ran 100 train steps in 20.49 secs\nStep   7800: train TripletLoss |  0.38176742\nStep   7800: eval  TripletLoss |  1.26928413\n\nStep   7900: Ran 100 train steps in 21.19 secs\nStep   7900: train TripletLoss |  0.43702799\nStep   7900: eval  TripletLoss |  0.59990001\n\nStep   8000: Ran 100 train steps in 20.90 secs\nStep   8000: train TripletLoss |  0.43291146\nStep   8000: eval  TripletLoss |  1.06215191\n\nStep   8100: Ran 100 train steps in 20.47 secs\nStep   8100: train TripletLoss |  0.40730411\nStep   8100: eval  TripletLoss |  0.53440797\n\nStep   8200: Ran 100 train steps in 20.90 secs\nStep   8200: train TripletLoss |  0.40646124\nStep   8200: eval  TripletLoss |  1.20116401\n\nStep   8300: Ran 100 train steps in 21.09 secs\nStep   8300: train TripletLoss |  0.42230201\nStep   8300: eval  TripletLoss |  0.81137216\n\nStep   8400: Ran 100 train steps in 20.54 secs\nStep   8400: train TripletLoss |  0.40382874\nStep   8400: eval  TripletLoss |  0.83521259\n\nStep   8500: Ran 100 train steps in 21.01 secs\nStep   8500: train TripletLoss |  0.43233740\nStep   8500: eval  TripletLoss |  1.20819664\n\nStep   8600: Ran 100 train steps in 21.05 secs\nStep   8600: train TripletLoss |  0.38162795\nStep   8600: eval  TripletLoss |  1.36262000\n\nStep   8700: Ran 100 train steps in 20.72 secs\nStep   8700: train TripletLoss |  0.40533775\nStep   8700: eval  TripletLoss |  3.90473509\n\nStep   8800: Ran 100 train steps in 20.82 secs\nStep   8800: train TripletLoss |  0.36313906\nStep   8800: eval  TripletLoss |  0.42090267\n\nStep   8900: Ran 100 train steps in 20.92 secs\nStep   8900: train TripletLoss |  0.39107296\nStep   8900: eval  TripletLoss |  1.03798318\n\nStep   9000: Ran 100 train steps in 20.48 secs\nStep   9000: train TripletLoss |  0.39688110\nStep   9000: eval  TripletLoss |  0.93492830\n\nStep   9100: Ran 100 train steps in 20.94 secs\nStep   9100: train TripletLoss |  0.41272277\nStep   9100: eval  TripletLoss |  0.54035962\n\nStep   9200: Ran 100 train steps in 20.92 secs\nStep   9200: train TripletLoss |  0.36429861\nStep   9200: eval  TripletLoss |  0.94934136\n\nStep   9300: Ran 100 train steps in 20.52 secs\nStep   9300: train TripletLoss |  0.38907313\nStep   9300: eval  TripletLoss |  0.57100636\n\nStep   9400: Ran 100 train steps in 21.18 secs\nStep   9400: train TripletLoss |  0.38233978\nStep   9400: eval  TripletLoss |  0.63917625\n\nStep   9500: Ran 100 train steps in 20.90 secs\nStep   9500: train TripletLoss |  0.35793141\nStep   9500: eval  TripletLoss |  1.28038478\n\nStep   9600: Ran 100 train steps in 20.53 secs\nStep   9600: train TripletLoss |  0.33650330\nStep   9600: eval  TripletLoss |  0.80242294\n\nStep   9700: Ran 100 train steps in 21.04 secs\nStep   9700: train TripletLoss |  0.38473177\nStep   9700: eval  TripletLoss |  0.55815589\n\nStep   9800: Ran 100 train steps in 20.90 secs\nStep   9800: train TripletLoss |  0.32640854\nStep   9800: eval  TripletLoss |  0.66070443\n\nStep   9900: Ran 100 train steps in 20.65 secs\nStep   9900: train TripletLoss |  0.40016535\nStep   9900: eval  TripletLoss |  0.50826091\n\nStep  10000: Ran 100 train steps in 20.90 secs\nStep  10000: train TripletLoss |  0.36041155\nStep  10000: eval  TripletLoss |  3.90245056\n\nStep  10100: Ran 100 train steps in 20.69 secs\nStep  10100: train TripletLoss |  0.37094444\nStep  10100: eval  TripletLoss |  0.21654010\n\nStep  10200: Ran 100 train steps in 20.46 secs\nStep  10200: train TripletLoss |  0.31786910\nStep  10200: eval  TripletLoss |  1.33906114\n\nStep  10300: Ran 100 train steps in 20.96 secs\nStep  10300: train TripletLoss |  0.35842147\nStep  10300: eval  TripletLoss |  1.15313148\n\nStep  10400: Ran 100 train steps in 20.77 secs\nStep  10400: train TripletLoss |  0.35277531\nStep  10400: eval  TripletLoss |  0.54467684\n\nStep  10500: Ran 100 train steps in 20.31 secs\nStep  10500: train TripletLoss |  0.33769539\nStep  10500: eval  TripletLoss |  0.42839622\n\nStep  10600: Ran 100 train steps in 20.97 secs\nStep  10600: train TripletLoss |  0.31542537\nStep  10600: eval  TripletLoss |  1.15192795\n\nStep  10700: Ran 100 train steps in 20.65 secs\nStep  10700: train TripletLoss |  0.32060030\nStep  10700: eval  TripletLoss |  0.70915878\n\nStep  10800: Ran 100 train steps in 20.38 secs\nStep  10800: train TripletLoss |  0.31435406\nStep  10800: eval  TripletLoss |  0.95897400\n\nStep  10900: Ran 100 train steps in 20.99 secs\nStep  10900: train TripletLoss |  0.33184522\nStep  10900: eval  TripletLoss |  0.83906639\n\nStep  11000: Ran 100 train steps in 20.85 secs\nStep  11000: train TripletLoss |  0.35410616\nStep  11000: eval  TripletLoss |  0.75934899\n\nStep  11100: Ran 100 train steps in 20.52 secs\nStep  11100: train TripletLoss |  0.36109775\nStep  11100: eval  TripletLoss |  0.74802375\n\nStep  11200: Ran 100 train steps in 21.06 secs\nStep  11200: train TripletLoss |  0.33805045\nStep  11200: eval  TripletLoss |  0.68777275\n\nStep  11300: Ran 100 train steps in 20.69 secs\nStep  11300: train TripletLoss |  0.35431361\nStep  11300: eval  TripletLoss |  2.93190861\n\nStep  11400: Ran 100 train steps in 20.54 secs\nStep  11400: train TripletLoss |  0.31427294\nStep  11400: eval  TripletLoss |  0.96736658\n\nStep  11500: Ran 100 train steps in 20.74 secs\nStep  11500: train TripletLoss |  0.32708153\nStep  11500: eval  TripletLoss |  1.55742729\n\nStep  11600: Ran 100 train steps in 20.39 secs\nStep  11600: train TripletLoss |  0.27413273\nStep  11600: eval  TripletLoss |  0.61524230\n\nStep  11700: Ran 100 train steps in 20.87 secs\nStep  11700: train TripletLoss |  0.32882205\nStep  11700: eval  TripletLoss |  0.89245361\n\nStep  11800: Ran 100 train steps in 20.93 secs\nStep  11800: train TripletLoss |  0.30385867\nStep  11800: eval  TripletLoss |  0.53175801\n\nStep  11900: Ran 100 train steps in 20.15 secs\nStep  11900: train TripletLoss |  0.30922529\nStep  11900: eval  TripletLoss |  0.68072581\n\nStep  12000: Ran 100 train steps in 21.03 secs\nStep  12000: train TripletLoss |  0.31814212\nStep  12000: eval  TripletLoss |  0.74308795\n\nStep  12100: Ran 100 train steps in 20.80 secs\nStep  12100: train TripletLoss |  0.34405503\nStep  12100: eval  TripletLoss |  0.41856909\n\nStep  12200: Ran 100 train steps in 20.53 secs\nStep  12200: train TripletLoss |  0.31075627\nStep  12200: eval  TripletLoss |  0.67231429\n\nStep  12300: Ran 100 train steps in 20.75 secs\nStep  12300: train TripletLoss |  0.37059519\nStep  12300: eval  TripletLoss |  0.81888753\n\nStep  12400: Ran 100 train steps in 20.66 secs\nStep  12400: train TripletLoss |  0.35189587\nStep  12400: eval  TripletLoss |  0.51585943\n\nStep  12500: Ran 100 train steps in 20.40 secs\nStep  12500: train TripletLoss |  0.28886902\nStep  12500: eval  TripletLoss |  3.25097084\n\nStep  12600: Ran 100 train steps in 20.86 secs\nStep  12600: train TripletLoss |  0.32586071\nStep  12600: eval  TripletLoss |  0.73220819\n\nStep  12700: Ran 100 train steps in 20.66 secs\nStep  12700: train TripletLoss |  0.30671299\nStep  12700: eval  TripletLoss |  0.68151736\n\nStep  12800: Ran 100 train steps in 20.51 secs\nStep  12800: train TripletLoss |  0.29314700\nStep  12800: eval  TripletLoss |  0.42838854\n\nStep  12900: Ran 100 train steps in 20.79 secs\nStep  12900: train TripletLoss |  0.29976767\nStep  12900: eval  TripletLoss |  1.15576363\n\nStep  13000: Ran 100 train steps in 20.78 secs\nStep  13000: train TripletLoss |  0.31792870\nStep  13000: eval  TripletLoss |  0.63461745\n\nStep  13100: Ran 100 train steps in 20.39 secs\nStep  13100: train TripletLoss |  0.33802715\nStep  13100: eval  TripletLoss |  0.31217921\n\nStep  13200: Ran 100 train steps in 20.86 secs\nStep  13200: train TripletLoss |  0.28301930\nStep  13200: eval  TripletLoss |  0.65287888\n\nStep  13300: Ran 100 train steps in 20.59 secs\nStep  13300: train TripletLoss |  0.31909677\nStep  13300: eval  TripletLoss |  0.66028607\n\nStep  13400: Ran 100 train steps in 20.47 secs\nStep  13400: train TripletLoss |  0.31030592\nStep  13400: eval  TripletLoss |  0.89797890\n\nStep  13500: Ran 100 train steps in 20.87 secs\nStep  13500: train TripletLoss |  0.30123854\nStep  13500: eval  TripletLoss |  0.41983479\n\nStep  13600: Ran 100 train steps in 20.72 secs\nStep  13600: train TripletLoss |  0.31626567\nStep  13600: eval  TripletLoss |  0.71699899\n\nStep  13700: Ran 100 train steps in 20.50 secs\nStep  13700: train TripletLoss |  0.27615950\nStep  13700: eval  TripletLoss |  0.72758132\n\nStep  13800: Ran 100 train steps in 20.98 secs\nStep  13800: train TripletLoss |  0.26062262\nStep  13800: eval  TripletLoss |  2.88658762\n\nStep  13900: Ran 100 train steps in 20.75 secs\nStep  13900: train TripletLoss |  0.28597197\nStep  13900: eval  TripletLoss |  0.73444533\n\nStep  14000: Ran 100 train steps in 20.45 secs\nStep  14000: train TripletLoss |  0.28432485\nStep  14000: eval  TripletLoss |  0.78050202\n\nStep  14100: Ran 100 train steps in 20.97 secs\nStep  14100: train TripletLoss |  0.30624717\nStep  14100: eval  TripletLoss |  1.23918581\n\nStep  14200: Ran 100 train steps in 20.46 secs\nStep  14200: train TripletLoss |  0.28897250\nStep  14200: eval  TripletLoss |  0.35411832\n\nStep  14300: Ran 100 train steps in 20.85 secs\nStep  14300: train TripletLoss |  0.28812355\nStep  14300: eval  TripletLoss |  0.70142782\n\nStep  14400: Ran 100 train steps in 20.84 secs\nStep  14400: train TripletLoss |  0.29474816\nStep  14400: eval  TripletLoss |  0.92799902\n\nStep  14500: Ran 100 train steps in 20.35 secs\nStep  14500: train TripletLoss |  0.26477858\nStep  14500: eval  TripletLoss |  0.84486312\n\nStep  14600: Ran 100 train steps in 20.84 secs\nStep  14600: train TripletLoss |  0.28749019\nStep  14600: eval  TripletLoss |  0.65958571\n\nStep  14700: Ran 100 train steps in 20.79 secs\nStep  14700: train TripletLoss |  0.29531682\nStep  14700: eval  TripletLoss |  1.24199605\n\nStep  14800: Ran 100 train steps in 20.60 secs\nStep  14800: train TripletLoss |  0.24873748\nStep  14800: eval  TripletLoss |  0.79279816\n\nStep  14900: Ran 100 train steps in 20.97 secs\nStep  14900: train TripletLoss |  0.23956221\nStep  14900: eval  TripletLoss |  0.85912251\n\nStep  15000: Ran 100 train steps in 20.59 secs\nStep  15000: train TripletLoss |  0.31610718\nStep  15000: eval  TripletLoss |  1.03513694\n\nStep  15100: Ran 100 train steps in 20.45 secs\nStep  15100: train TripletLoss |  0.30241650\nStep  15100: eval  TripletLoss |  0.38819939\n\nStep  16000: Ran 100 train steps in 20.40 secs\nStep  16000: train TripletLoss |  0.27705288\nStep  16000: eval  TripletLoss |  1.01118934\n\nStep  16100: Ran 100 train steps in 20.92 secs\nStep  16100: train TripletLoss |  0.26549166\nStep  16100: eval  TripletLoss |  0.87764752\n\nStep  16200: Ran 100 train steps in 20.66 secs\nStep  16200: train TripletLoss |  0.28126448\nStep  16200: eval  TripletLoss |  0.32933527\n\nStep  16300: Ran 100 train steps in 20.46 secs\nStep  16300: train TripletLoss |  0.27939755\nStep  16300: eval  TripletLoss |  0.83320522\n\nStep  16400: Ran 100 train steps in 20.80 secs\nStep  16400: train TripletLoss |  0.28790253\nStep  16400: eval  TripletLoss |  1.14031339\n\nStep  16500: Ran 100 train steps in 20.86 secs\nStep  16500: train TripletLoss |  0.27437881\nStep  16500: eval  TripletLoss |  3.70489812\n\nStep  16600: Ran 100 train steps in 20.31 secs\nStep  16600: train TripletLoss |  0.26469955\nStep  16600: eval  TripletLoss |  0.64968377\n\nStep  16700: Ran 100 train steps in 20.96 secs\nStep  16700: train TripletLoss |  0.22686982\nStep  16700: eval  TripletLoss |  0.42288548\n\nStep  16800: Ran 100 train steps in 20.93 secs\nStep  16800: train TripletLoss |  0.23500143\nStep  16800: eval  TripletLoss |  0.92005491\n\nStep  16900: Ran 100 train steps in 20.51 secs\nStep  16900: train TripletLoss |  0.25408429\nStep  16900: eval  TripletLoss |  0.51987195\n\nStep  17000: Ran 100 train steps in 20.72 secs\nStep  17000: train TripletLoss |  0.26649979\nStep  17000: eval  TripletLoss |  0.79432166\n\nStep  17100: Ran 100 train steps in 19.99 secs\nStep  17100: train TripletLoss |  0.27861974\nStep  17100: eval  TripletLoss |  0.85678536\n\nStep  17200: Ran 100 train steps in 20.84 secs\nStep  17200: train TripletLoss |  0.26759624\nStep  17200: eval  TripletLoss |  0.58104682\n\nStep  17300: Ran 100 train steps in 20.66 secs\nStep  17300: train TripletLoss |  0.27764532\nStep  17300: eval  TripletLoss |  0.41499996\n\nStep  17400: Ran 100 train steps in 20.20 secs\nStep  17400: train TripletLoss |  0.29766884\nStep  17400: eval  TripletLoss |  1.12296391\n\nStep  17500: Ran 100 train steps in 20.63 secs\nStep  17500: train TripletLoss |  0.26638439\nStep  17500: eval  TripletLoss |  1.08800077\n\nStep  17600: Ran 100 train steps in 20.43 secs\nStep  17600: train TripletLoss |  0.23705299\nStep  17600: eval  TripletLoss |  0.40917099\n\nStep  17700: Ran 100 train steps in 20.22 secs\nStep  17700: train TripletLoss |  0.23786126\nStep  17700: eval  TripletLoss |  3.20888472\n\nStep  17800: Ran 100 train steps in 20.54 secs\nStep  17800: train TripletLoss |  0.26117817\nStep  17800: eval  TripletLoss |  0.62577838\n\nStep  17900: Ran 100 train steps in 20.50 secs\nStep  17900: train TripletLoss |  0.21885210\nStep  17900: eval  TripletLoss |  0.34845942\n\nStep  18000: Ran 100 train steps in 20.31 secs\nStep  18000: train TripletLoss |  0.26576871\nStep  18000: eval  TripletLoss |  0.98786676\n\nStep  18100: Ran 100 train steps in 20.54 secs\nStep  18100: train TripletLoss |  0.24863252\nStep  18100: eval  TripletLoss |  0.99892062\n\nStep  18200: Ran 100 train steps in 20.54 secs\nStep  18200: train TripletLoss |  0.28671533\nStep  18200: eval  TripletLoss |  0.47320777\n\nStep  18300: Ran 100 train steps in 20.29 secs\nStep  18300: train TripletLoss |  0.22038685\nStep  18300: eval  TripletLoss |  0.40438843\n\nStep  18400: Ran 100 train steps in 20.65 secs\nStep  18400: train TripletLoss |  0.29110643\nStep  18400: eval  TripletLoss |  1.69157493\n\nStep  18500: Ran 100 train steps in 20.50 secs\nStep  18500: train TripletLoss |  0.26060370\nStep  18500: eval  TripletLoss |  0.87238789\n\nStep  18600: Ran 100 train steps in 20.02 secs\nStep  18600: train TripletLoss |  0.24955559\nStep  18600: eval  TripletLoss |  0.34804353\n","output_type":"stream"}]},{"cell_type":"code","source":"def cos_similarity(v1,v2):\n    similarity=np.matmul(v1,v2.T)\n    return similarity","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:41.371542Z","iopub.execute_input":"2023-06-02T18:06:41.371879Z","iopub.status.idle":"2023-06-02T18:06:41.379969Z","shell.execute_reply.started":"2023-06-02T18:06:41.371846Z","shell.execute_reply":"2023-06-02T18:06:41.376845Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def predict(model,question,threshold=.7):\n    \n    result=''\n    \n    question1,question2=get_tensor(question)\n    \n    question1,question2=np.expand_dims(question1,axis=0),np.expand_dims(question2,axis=0)\n    \n    v1,v2=model.eval_model([question1,question2])\n    \n    similarity=cos_similarity(v1,v2)[0][0]\n    print('The Similarity is:',similarity)\n    \n    result='Similarity' if similarity>threshold else 'DisSimilarity'\n    \n    return result    ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:41.381469Z","iopub.execute_input":"2023-06-02T18:06:41.381811Z","iopub.status.idle":"2023-06-02T18:06:41.397230Z","shell.execute_reply.started":"2023-06-02T18:06:41.381778Z","shell.execute_reply":"2023-06-02T18:06:41.396334Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"question=['How are you doing','how are you']\nquestion1,question2=get_tensor(question)\npredict(model,question)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:41.398383Z","iopub.execute_input":"2023-06-02T18:06:41.398926Z","iopub.status.idle":"2023-06-02T18:06:42.785334Z","shell.execute_reply.started":"2023-06-02T18:06:41.398892Z","shell.execute_reply":"2023-06-02T18:06:42.784318Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The Similarity is: 0.7493155\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'Similarity'"},"metadata":{}}]},{"cell_type":"code","source":"question=['what your name','how old are you']\npredict(model,question)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:42.786892Z","iopub.execute_input":"2023-06-02T18:06:42.787931Z","iopub.status.idle":"2023-06-02T18:06:43.221500Z","shell.execute_reply.started":"2023-06-02T18:06:42.787893Z","shell.execute_reply":"2023-06-02T18:06:43.220467Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"The Similarity is: 0.08664571\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'DisSimilarity'"},"metadata":{}}]},{"cell_type":"code","source":"question=['What is the story of Kohinoor (Koh-i-Noor) Dia...','What would happen if the Indian government sto...']\npredict(model,question)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:43.223333Z","iopub.execute_input":"2023-06-02T18:06:43.224088Z","iopub.status.idle":"2023-06-02T18:06:44.228188Z","shell.execute_reply.started":"2023-06-02T18:06:43.224048Z","shell.execute_reply":"2023-06-02T18:06:44.227202Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"The Similarity is: 0.19641636\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'DisSimilarity'"},"metadata":{}}]},{"cell_type":"code","source":"generate_test_data=trax.data.BucketByLength(boundaries=[512],batch_sizes=[len(x_test)],length_keys=[0,1])(generator(x_test))\nx_test=next(generate_test_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:44.229758Z","iopub.execute_input":"2023-06-02T18:06:44.230117Z","iopub.status.idle":"2023-06-02T18:06:44.761542Z","shell.execute_reply.started":"2023-06-02T18:06:44.230083Z","shell.execute_reply":"2023-06-02T18:06:44.760536Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def compute_accuracy(x_test,y_test,threshold=.7):\n    accuracy=0\n    y_test=y_test.values\n    v1,v2=model.eval_model(x_test)\n    for idx,(vector1,vector2) in enumerate(zip(v1,v2)):\n        value=0\n        similarity=cos_similarity(vector1,vector2)\n        value=1  if similarity>threshold else 0\n    \n            \n        if value ==y_test[idx]:\n            accuracy+=1\n    return(accuracy/len(y_test))\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:44.762909Z","iopub.execute_input":"2023-06-02T18:06:44.763668Z","iopub.status.idle":"2023-06-02T18:06:44.771890Z","shell.execute_reply.started":"2023-06-02T18:06:44.763631Z","shell.execute_reply":"2023-06-02T18:06:44.771027Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print('The Accurcy is:',compute_accuracy(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T18:06:44.773106Z","iopub.execute_input":"2023-06-02T18:06:44.773842Z","iopub.status.idle":"2023-06-02T18:06:48.513493Z","shell.execute_reply.started":"2023-06-02T18:06:44.773806Z","shell.execute_reply":"2023-06-02T18:06:48.512418Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"The Accurcy is: 0.7555110220440882\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}